Multi-Modal AI Assistant ğŸ¤ğŸ–¼ï¸ğŸ’¬

A Python-based multimodal assistant supporting text, audio, and image queries using OpenAI API + Streamlit.

ğŸš€ Features

Chat with AI using text

Upload images for analysis

Send audio and get transcription + response

Streamlit frontend

Modular backend

Clean architecture

ğŸ“Œ Project Structure
multi-modal-assistant/
â”œâ”€â”€ server/
â”œâ”€â”€ models/
â”œâ”€â”€ utils/
â”œâ”€â”€ output/   <-- results, screenshots
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸ› ï¸ How to Run
git clone <your-repo-url>
cd multi-modal-assistant
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
streamlit run server/ui_app.py

ğŸ“¸ Output Screenshots

(Put your actual screenshots inside /output folder)