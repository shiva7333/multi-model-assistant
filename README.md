

```
multi-modal-assistant/README.md
```

---

# âœ… **README.md **

---

# ğŸŒŸ **ShivaGPT â€” Your Personal Voiceâ€“Visionâ€“Text AI Assistant**

ShivaGPT is an advanced **multi-modal AI assistant** that can understand **text**, analyze **images**, and transcribe **audio**, all inside a clean Streamlit UI.
Built using OpenAIâ€™s latest models, ShivaGPT serves as a personal productivity tool capable of summarization, reasoning, content creation, and more.

---

## ğŸš€ **Features**

### ğŸ”¤ Text Intelligence

* Smart text-based chat
* Summaries, rewriting, Q&A, explanations
* Generates professional posts, ideas, answers

### ğŸ–¼ï¸ Image Intelligence

* Understands uploaded images
* Generates captions, summaries, descriptions
* Extracts insight from posters, documents, screenshots

### ğŸ¤ Audio Intelligence

* Transcribes audio (mp3/wav) using Whisper
* Converts speech to text
* Supports long-form audio transcription

### ğŸ§  Multi-Modal Fusion

* Takes **text + image + audio** together
* Produces context-aware intelligent responses

### ğŸ¨ Clean Streamlit UI

* Simple interface
* File upload for audio & images
* Real-time response display

---

## ğŸ“ **Project Structure**

```
shivaGPT/
â”‚â”€â”€ server/
â”‚     â”œâ”€â”€ core_engine.py        # Main model logic
â”‚     â”œâ”€â”€ audio_processor.py    # Whisper audio handler
â”‚     â”œâ”€â”€ image_processor.py    # Image captioning/extraction
â”‚     â”œâ”€â”€ settings.py           # API keys & config
â”‚     â”œâ”€â”€ ui_app.py             # Streamlit frontend
â”‚
â”‚â”€â”€ output/                     # Screenshots, demo outputs
â”‚â”€â”€ .gitignore
â”‚â”€â”€ README.md
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ venv/ (ignored in git)
```

---

## ğŸ”§ **Tech Stack**

| Component           | Technology        |
| ------------------- | ----------------- |
| Frontend UI         | Streamlit         |
| LLM                 | OpenAI GPT Models |
| Image Processing    | OpenAI Vision     |
| Audio Transcription | Whisper API       |
| Backend             | Python 3.11       |
| Environment         | Virtualenv        |

---

## ğŸ› ï¸ **Installation Guide (Local Setup)**

### **1ï¸âƒ£ Clone the Repository**

```bash
git clone https://github.com/YOUR_USERNAME/shivaGPT.git
cd shivaGPT
```

---

### **2ï¸âƒ£ Create Virtual Environment**

```bash
python -m venv venv
```

Activate it:

**Windows**

```bash
.\venv\Scripts\activate
```

---

### **3ï¸âƒ£ Install Dependencies**

```bash
pip install -r requirements.txt
```

---

### **4ï¸âƒ£ Add Your OpenAI API Key**

Create file:

```
server/settings.py
```

Add:

```python
OPENAI_API_KEY = "your-key-here"
```

---

### **5ï¸âƒ£ Run the Application**

```bash
streamlit run server/ui_app.py
```

The interface will open in your browser.

---

## ğŸ–¼ï¸ **Demo Output Screenshots**

Store your screenshots inside:

```
output/
```

Example preview (add real screenshots after running):

```
output/
â”‚â”€â”€ ui_home.png
â”‚â”€â”€ image_summary_result.png
â”‚â”€â”€ audio_to_text_result.png
```

---

## ğŸ§© **How It Works (Architecture)**

```
User Input
   â”‚
   â”œâ”€â”€ Text â†’ LLM
   â”œâ”€â”€ Image â†’ Vision Model
   â”œâ”€â”€ Audio â†’ Whisper Transcription
   â”‚
   â–¼
Core Engine Combines All Inputs
   â”‚
   â–¼
OpenAI Multi-Modal Model Generates Response
   â”‚
   â–¼
Streamlit UI Displays Final Answer
```

---

## ğŸ¤ **Contributing**

Contributions are welcome!

1. Fork the repo
2. Create a new branch
3. Commit your changes
4. Open a Pull Request

---

## ğŸ“œ **License**

This project is licensed under the **MIT License** â€” free for personal & commercial use.

---
